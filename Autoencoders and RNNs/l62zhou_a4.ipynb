{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4: Autoencoders and RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import Network as Network\n",
    "import mnist_loader\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q1: Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Derivative of Cosine Proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Loss function is\n",
    "$$\n",
    "C ( \\vec{y} , \\vec{t} ) = \\frac{ - \\left( \\vec{y} \\cdot \\vec{t} \\right) }{ \\| \\vec{y} \\| \\ \\| \\vec{t} \\|}\n",
    "$$\n",
    "We are given that the output layer uses the identity mapping as an activation function, $\\vec{y} = \\vec{z}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial C}{\\partial {y_i}} = - \n",
    "\\frac {{\\left(|\\vec{y}| \\cdot |\\vec{t}| \\right)} \\cdot {t_i} + \n",
    "\\frac {{2y_i} \\cdot { \\|  \\vec{t} \\|}} {2 \\| \\vec{y} \\|} \\cdot \\vec{y} \\cdot \\vec{t}\n",
    "} {\n",
    "\t{\\| \\vec{y} \\| ^2} \t{\\| \\vec{t} \\| ^2} \n",
    "}\n",
    "= - \\frac {t_i} {{\\|\\vec{y}\\|}{\\|\\vec{t}\\|}} - C ( \\vec{y} , \\vec{t} ) \\cdot \\frac {y_i} {\\| \\vec{y} \\| ^2} \n",
    "\\end{align}\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial \\vec{y}} = - \\frac {t} {{\\|\\vec{y}\\|}{\\|\\vec{t}\\|}} - C ( \\vec{y} , \\vec{t} ) \\cdot \\frac {y} {\\| \\vec{y} \\| ^2} \n",
    "\\end{align}\n",
    "$$  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (b) Implement Derivative of Cosine Proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cosine Proximity\n",
    "def CosineProximity(y, t):\n",
    "    '''\n",
    "        C = CosineProximity(y, t)\n",
    "        \n",
    "        Evaluates the average cosine proximity for the batch.\n",
    "        \n",
    "        Inputs:\n",
    "          y is a batch of samples, with samples stored in rows\n",
    "          t is a batch of targets\n",
    "          \n",
    "        Output:\n",
    "          C is the average cosine proximity (cost)\n",
    "    '''\n",
    "    C = -np.sum(y*t, axis=1)\n",
    "    C /= np.linalg.norm(y, axis=1)\n",
    "    C /= np.linalg.norm(t, axis=1)\n",
    "    return np.sum(C) / Network.NSamples(y)\n",
    "\n",
    "\n",
    "# CosineProximity_p\n",
    "def CosineProximity_p(y, t):\n",
    "    '''\n",
    "        dCdy = CosineProximity_p(y, t)\n",
    "        \n",
    "        Computes the gradient of the cosine proximity cost function.\n",
    "        \n",
    "        Inputs:\n",
    "          y is a batch of samples, with samples stored in rows\n",
    "          t is a batch of targets\n",
    "          \n",
    "        Output:\n",
    "          dCdy is an array the same size as y, holding the derivative\n",
    "               of the cost with respect to each element in y\n",
    "    '''\n",
    "    \n",
    "    # ***** YOUR CODE HERE *****\n",
    "    \n",
    "    dCdy = np.zeros_like(y)  # replace this line of code\n",
    "    \n",
    "    return dCdy\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (c) Create and Train a Network\n",
    "You can make your network use your cost function and its derivative by setting the member variables,\n",
    "\n",
    "    mynet.cost = CosineProximity\n",
    "    mynet.cost_p = CosineProximity_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read in 10000 MNIST samples\n",
    "train, validate, test = mnist_loader.load_data_wrapper()\n",
    "train_in = np.array(train[0][:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some sample digit images\n",
    "plt.figure(figsize=[15,4])\n",
    "n_digits = 4\n",
    "for n in range(n_digits):\n",
    "    idx = np.random.randint(10000)\n",
    "    plt.subplot(2,n_digits,n+1)\n",
    "    plt.imshow(np.reshape(train_in[idx], [28,28]), cmap='gray'); plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The traing cost is -0.02657500755830507\n"
     ]
    }
   ],
   "source": [
    " # ***** YOUR CODE HERE *****\n",
    "target = train_in\n",
    "mynet = Network.Network()\n",
    "# input layer\n",
    "mynet.AddLayer(Network.Layer(784)) \n",
    "# hidden layer\n",
    "mynet.AddLayer(Network.Layer(50, act = 'logistic'))\n",
    "# output layer\n",
    "mynet.AddLayer(Network.Layer(784, act = 'logistic'))\n",
    "# train data\n",
    "mynet.SGD(train_in, train_in, batch_size=50, epochs=100, lrate=1.)\n",
    "print(\"The traing cost is \" + str(net.Evaluate(train_in, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (d) View Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some sample digit images\n",
    "plt.figure(figsize=[15,4])\n",
    "n_digits = 9\n",
    "output = mynet.FeedForward(test[0][:10000])\n",
    "for n in range(n_digits):\n",
    "    idx = np.random.randint(10000)\n",
    "    plt.subplot(2,n_digits,n+1)\n",
    "    plt.imshow(np.reshape(output[idx], [28,28]), cmap='gray'); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q2: BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial V} =  \\sum_{i=1}^{\\tau} \\frac {\\partial C(y^i,t^i)}{\\partial V} \n",
    "= \\sum_{i=1}^{\\tau}\\frac{\\partial C(y^i,t^i)}{\\partial y^i}\\odot\\frac{dy^i}{dz^i}\\frac{\\partial z^i}{\\partial V}\n",
    "= \\sum_{i=1}^{\\tau}\\frac{\\partial C(y^i,t^i)}{\\partial y^i} \\odot \\sigma' (z^i)(h^i)^T \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial U} = \\sum_{i=1}^{\\tau}\\frac{\\partial E(y^i,t^i)}{\\partial h^i}\\odot\\frac{dh^i}{ds^i}\\frac{\\partial s^i}{\\partial U}\n",
    "=\\sum_{i=1}^{\\tau}(\\frac{\\partial E}{\\partial h^i}\\odot\\sigma'(s^i))(x^i)^T\n",
    "\\end{align}\n",
    "$$\n",
    "\\begin{align}\n",
    "since \n",
    "\\end{align} \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "s = Ux + Wh +b \n",
    "\\end{align} \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "and \n",
    "\\end{align} \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "s = Ux + Wh +b \n",
    "\\end{align} \n",
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial W} = \\sum_{i=1}^{\\tau - 1}\\frac{\\partial E(y^i,t^i)}{\\partial h^{i+1}}\\odot\\frac{dh^{i+1}}{ds^{i+1}}\\frac{\\partial s^{i+1}}{\\partial W} = \\sum_{i=1}^{\\tau -1}(\\frac{\\partial E}{\\partial h^{i+1}}\\odot\\sigma'(s^{i+1}))(h^i)^T\n",
    "\\end{align}\n",
    "$$\n",
    "\\begin{align}\n",
    "since \n",
    "\\end{align} \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "s = Ux + Wh +b \n",
    "\\end{align} \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "and \n",
    "\\end{align} \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "s = Ux + Wh +b \n",
    "\\end{align} \n",
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b} = \\sum_{i=1}^{\\tau}\\frac{\\partial E(y^i,t^i)}{\\partial h^i}\\odot\\frac{dh^i}{ds^i}\\frac{\\partial s^i}{\\partial b}\n",
    "= \\sum_{i=1}^{\\tau}(\\frac{\\partial E}{\\partial h^{i}}\\odot\\sigma'(s^{i}))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Q3: RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below creates two lists:\n",
    "  - `sentences`, and\n",
    "  - `next_chars`\n",
    "  \n",
    "Each list element represents a sequences of characters. There are 3 ways to represent a character:\n",
    "1. As a string, eg. `'b'`\n",
    "2. As an index to a character set, eg. `2`\n",
    "3. As a one-hot vector, eg. `[0, 0, 1, 0, ...]`\n",
    "\n",
    "The lists `sentences` and `next_chars` store the characters as indices (item 2 above). The utility functions\n",
    "  - `char2vec`\n",
    "  - `index2vec`\n",
    "  - `vec2char`\n",
    "  - `vec2index`\n",
    "  \n",
    "transform the characters between the 3 representations. You can also use the dictionaries `char_indices` and `indices_char` to convert between a string character and and index. The code below contains some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character set:  abcdefghijklmnopqrstuvwxyz (first char is a space)\n",
      "There are 27 characters in our character set\n",
      "Here is how you can view one of the samples:\n",
      "Sample input: [on the ori]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = open('origin_of_species.txt').read().lower()\n",
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0, \"\\0\") #Add newline character\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "# Let's simplify it by keeping only letters and spaces\n",
    "filt_idx = []\n",
    "for i in idx:\n",
    "    if i<=24:\n",
    "        filt_idx.append(2)\n",
    "    elif i>24:\n",
    "        filt_idx.append(i)\n",
    "blah = ''.join([indices_char[f] for f in filt_idx])\n",
    "text = re.sub(' +', ' ', blah)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('Character set: '+''.join(chars)+' (first char is a space)')\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "print('There are '+str(vocab_size)+' characters in our character set')\n",
    "\n",
    "''.join(indices_char[i] for i in idx[:70])\n",
    "\n",
    "def char2vec(c):\n",
    "    v = np.zeros(vocab_size)\n",
    "    v[char_indices[c]] = 1.\n",
    "    return v\n",
    "\n",
    "def index2vec(i):\n",
    "    v = np.zeros(vocab_size)\n",
    "    v[i] = 1.\n",
    "    return v\n",
    "\n",
    "def vec2index(v):\n",
    "    i = np.argmax(v)\n",
    "    return i\n",
    "\n",
    "def vec2char(v):\n",
    "    return indices_char[vec2index(v)]\n",
    "\n",
    "'''Form the dataset in sentences'''\n",
    "sentences_length = 10\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, 10000 - sentences_length + 1):\n",
    "    sentences.append(idx[i: i + sentences_length]) #Assume a sentence is made of X characters\n",
    "    next_chars.append(idx[i + 1: i + sentences_length + 1]) #Offset by 1 to the right for the target\n",
    "\n",
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])\n",
    "sentences.shape, next_chars.shape\n",
    "\n",
    "def read_sentence(idx):\n",
    "    return ''.join(indices_char[i] for i in idx)\n",
    "\n",
    "print('Here is how you can view one of the samples:')\n",
    "print('Sample input: ['+read_sentence(sentences[0])+']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return np.clip(z, a_min=0, a_max=None)  # ReLU\n",
    "    #return 1./(1+np.exp(-z))  # use this for logistic\n",
    "\n",
    "def sigma_primed(y):\n",
    "    return np.clip(np.sign(y), a_min=0, a_max=1)  # Derivative of ReLU\n",
    "    #return y*(1.-y)  # use this for logistic\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    denom = np.sum(ez)\n",
    "    return ez / denom\n",
    "\n",
    "def CrossEntropy(y, t):\n",
    "    return -sum(t*np.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Complete BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    \n",
    "    def __init__(self, dims, seq_length=10):\n",
    "        '''\n",
    "         Input:\n",
    "           dims is [X, H, Y], where the input has layer has X neurons, the\n",
    "                hidden layer has H neurons, and the output layer has Y neurons.\n",
    "           seq_length is how many steps to unroll the RNN through time\n",
    "                (this is the same as tau in the lecture notes)\n",
    "        '''\n",
    "        self.X, self.H, self.Y = dims\n",
    "        self.seq_length = seq_length\n",
    "        # Input layer\n",
    "        self.xs = [np.zeros(self.X) for x in range(seq_length)] # activity\n",
    "        # Hidden layer\n",
    "        self.hs = [np.zeros(self.H) for x in range(seq_length)] # activity\n",
    "        # Output layer\n",
    "        self.ys = [np.zeros(self.Y) for x in range(seq_length)] # activity\n",
    "        \n",
    "        # Connection weights\n",
    "        self.U = np.random.normal(size=[self.H, self.X])/np.sqrt(self.X) # input->hidden\n",
    "        self.W = np.random.normal(size=[self.H, self.H])/np.sqrt(self.H) # hidden->hidden\n",
    "        self.V = np.random.normal(size=[self.Y, self.H])/np.sqrt(self.H) # hidden->output\n",
    "        self.b = np.zeros(self.H) # biases for hidden nodes\n",
    "        self.c = np.zeros(self.Y) # biases for output nodes\n",
    "        \n",
    "    def ForwardTT(self, seq_in):\n",
    "        '''\n",
    "         i = ForwardTT(seq_in)\n",
    "        \n",
    "         Propagates the RNN forward through time, saving all the intermediate\n",
    "         states that will be needed for backprop through time (BPTT).\n",
    "        \n",
    "         Input:\n",
    "           seq_in is a vector of indecies, with self.seq_length elements.\n",
    "        \n",
    "         Output:\n",
    "           i is the index of the character predicted to follow the input.\n",
    "         \n",
    "         This method's main purpose is to update the states of the activites\n",
    "         in the time-unrolled network.\n",
    "        '''\n",
    "        self.xs[0] = index2vec(seq_in[0]) # convert to character vector\n",
    "        \n",
    "        # Starting input current for hidden nodes\n",
    "        ss = np.dot(self.U, self.xs[0]) + self.b\n",
    "        self.hs[0] = sigma(ss)  # Activation of hidden nodes\n",
    "        \n",
    "        # Input current for output nodes\n",
    "        zs = np.dot(self.V, self.hs[0]) + self.c\n",
    "        self.ys[0] = softmax(zs)  # Activation of output nodes\n",
    "        \n",
    "        # Now process forward in time\n",
    "        for i in range(1, self.seq_length):\n",
    "            self.xs[i] = index2vec(seq_in[i])  # input vector\n",
    "            \n",
    "            # Input current for hidden nodes, including recurrent connections\n",
    "            ss = np.dot(self.U, self.xs[i]) + np.dot(self.W, self.hs[i-1]) + self.b\n",
    "            self.hs[i] = sigma(ss)  # Activation\n",
    "            \n",
    "            # Input current for output nodes\n",
    "            zs = np.dot(self.V, self.hs[i]) + self.c\n",
    "            self.ys[i] = softmax(zs)  # Activation\n",
    "            \n",
    "        # Might as well output the final state of the output\n",
    "        return vec2index(self.ys[-1])\n",
    "    \n",
    "    \n",
    "    def BPTT(self, seq_in, seq_out):\n",
    "        '''\n",
    "         BPTT(seq_in, seq_out)\n",
    "         \n",
    "         Performs backprop through time on one sample given by the input and\n",
    "         output sequence.\n",
    "         \n",
    "         Input:\n",
    "           seq_in is a vector of indices specifying the input sequence of\n",
    "                   characters.\n",
    "           seq_out is a vector of indices specifying the output sequence of\n",
    "                   characters. Typically, seq_out is the same as seq_in, but\n",
    "                   shifted by 1 character.\n",
    "         \n",
    "         Output:\n",
    "           None, but the connection weights and biases are updated.\n",
    "        '''\n",
    "        # Initialize gradients to zero\n",
    "        self.dEdV = np.zeros(np.shape(self.V))\n",
    "        self.dEdW = np.zeros(np.shape(self.W))\n",
    "        self.dEdU = np.zeros(np.shape(self.U))\n",
    "        self.dEdb = np.zeros(np.shape(self.b))\n",
    "        self.dEdc = np.zeros(np.shape(self.c))\n",
    "        self.dEdz = []\n",
    "        self.dEdf = []\n",
    "        for i in range(self.seq_length):\n",
    "            # convert to character vector\n",
    "            ithActivity = self.ys[i]\n",
    "            convertedCharVec= index2vec(seq_out[i])\n",
    "            self.dEdz.append(ithActivity - convertedCharVec)\n",
    "        # iniliazise dEdf with zero which has seq_length\n",
    "        self.dEdf = self.seq_length * [0]\n",
    "        counter = 0\n",
    "        for i in range(self.seq_length - 2, -1, -1):\n",
    "            if (counter == 0):\n",
    "                # iniliaze the first one from the back\n",
    "                self.dEdf[-1]=sigma_primed(self.hs[i])*((self.V.T@self.dEdz[i]))\n",
    "                # update counter \n",
    "                counter = counter+1 \n",
    "            self.dEdf[i] = sigma_primed(self.hs[i])*((self.V.T@self.dEdz[i])+(self.W.T@self.dEdf[i+1]))\n",
    "        for i in range(self.seq_length - 1):\n",
    "            self.dEdV += np.array([self.dEdz[i]]).T@np.array([self.hs[i]])\n",
    "            self.dEdU += np.array([self.dEdf[i]]).T@np.array([self.xs[i]])\n",
    "            self.dEdb += self.dEdf[i]\n",
    "            self.dEdc += self.dEdz[i]\n",
    "            self.dEdW += np.array([self.dEdf[i+1]]).T@np.array([self.hs[i]])\n",
    "            # handle special case\n",
    "            self.dEdV += np.array([self.dEdz[i]]).T@np.array([self.hs[i]])\n",
    "            self.dEdU += np.array([self.dEdf[i]]).T@np.array([self.xs[i]])\n",
    "            self.dEdb += self.dEdf[i]\n",
    "            self.dEdc += self.dEdz[i]\n",
    "        \n",
    "            \n",
    "    def Generate(self, n=1):\n",
    "        '''\n",
    "         c = Generate(n=1)\n",
    "         \n",
    "         Runs the RNN from the last state after running ForwardTT, outputting\n",
    "         the next n characters.\n",
    "         \n",
    "         Input:\n",
    "           n is the number of characters you want to predict\n",
    "           \n",
    "         Output:\n",
    "           c is a string of n characters\n",
    "        '''\n",
    "        y = self.ys[-1]  # Final output of ForwardTT\n",
    "        c = vec2char(y)  # Convert it to a character string\n",
    "        h = self.hs[-1]  # Starting with last hidden state...\n",
    "        # Loop forward in time\n",
    "        # (no need to record states, since we won't be doing BPTT)\n",
    "        for nn in range(n-1):\n",
    "            x = copy.copy(y)  # Use last output as next input\n",
    "            \n",
    "            # Input current for hidden nodes\n",
    "            s = np.dot(self.U, x) + np.dot(self.W, h) + self.b\n",
    "            h = sigma(s)  # Activation\n",
    "            \n",
    "            # Input current for output nodes\n",
    "            z = np.dot(self.V, h) + self.c\n",
    "            y = softmax(z)  # Activation\n",
    "            \n",
    "            # And add the next character to our output string\n",
    "            c += vec2char(y)\n",
    "            \n",
    "        return c\n",
    "            \n",
    "    def Evaluate(self, train_in, train_out):\n",
    "        '''\n",
    "         loss = Evaluate(train_in, train_out)\n",
    "         \n",
    "         Evaluates the network on the supplied dataset.\n",
    "         \n",
    "         Input:\n",
    "           train_in is a list of input sequences (see ForwardTT for format of input)\n",
    "           train_out is the corresponding list of output sequences\n",
    "           \n",
    "         Output:\n",
    "           loss is the average cross entropy\n",
    "        '''\n",
    "        val = 0.\n",
    "        for x, t in zip(train_in, train_out):\n",
    "            self.ForwardTT(x)\n",
    "            for i in range(self.seq_length):\n",
    "                val += CrossEntropy(self.ys[i], index2vec(t[i]))\n",
    "        return val/len(train_in)\n",
    "            \n",
    "    def Train(self, train_in, train_out, kappa=0.05, epochs=1):\n",
    "        '''\n",
    "         Train(train_in, train_out, kappa=0.05, epochs=1)\n",
    "         \n",
    "         Performs epochs of gradient descent, performing BPTT after each sample.\n",
    "         \n",
    "         Input:\n",
    "           train_in and train_out is the training dataset\n",
    "           kappa is the learning rate\n",
    "           epochs is the number of times to go through the dataset\n",
    "           \n",
    "         Output:\n",
    "           None, but the connection weights and biases are updated\n",
    "        '''\n",
    "        # Loop over epochs\n",
    "        for e in range(epochs):\n",
    "            \n",
    "            # Shuffle the training data\n",
    "            data_shuffled = list(zip(train_in, train_out))\n",
    "            np.random.shuffle(data_shuffled)\n",
    "            \n",
    "            for x, t in data_shuffled:\n",
    "                self.ForwardTT(x)  # Forward through time\n",
    "                self.BPTT(x, t)    # Backprop through time\n",
    "                # Note that BPTT starts by resetting the gradients to zero.\n",
    "                \n",
    "                # Apply update to connection weights and biases\n",
    "                self.V -= kappa*self.dEdV\n",
    "                self.U -= kappa*self.dEdU\n",
    "                self.W -= kappa*self.dEdW\n",
    "                self.b -= kappa*self.dEdb\n",
    "                self.c -= kappa*self.dEdc\n",
    "\n",
    "            print('Epoch '+str(e)+', Loss = '+str(self.Evaluate(train_in, train_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (b) Create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#net = RNN(...)\n",
    "net = RNN(dims = [27, 400, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (c) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 18.4826817775923\n",
      "Epoch 1, Loss = 15.719582108506078\n",
      "Epoch 2, Loss = 13.845576650293696\n",
      "Epoch 3, Loss = 12.502393166963577\n",
      "Epoch 4, Loss = 11.44682064256953\n",
      "Epoch 5, Loss = 10.585319295815296\n",
      "Epoch 6, Loss = 10.071332582331019\n",
      "Epoch 7, Loss = 9.403945594006261\n",
      "Epoch 8, Loss = 9.177879810174545\n",
      "Epoch 9, Loss = 8.872494205781106\n",
      "Epoch 10, Loss = 8.756106787369726\n",
      "Epoch 11, Loss = 8.514647179432663\n",
      "Epoch 12, Loss = 8.475980235654974\n",
      "Epoch 13, Loss = 8.179417568168551\n",
      "Epoch 14, Loss = 8.221532250137448\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# net.Train(...)\n",
    "net.Train(sentences, next_chars, kappa = 0.001, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You might opt to have more than one train command, using different\n",
    "# learning rates and numbers of epochs. Each one builds on the results\n",
    "# from the last run.\n",
    "#net.Train(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (d) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:      n introduc\n",
      "Prediction: n introduction \n",
      "Actual:     n introduction when \n"
     ]
    }
   ],
   "source": [
    "# A sample continuation.\n",
    "n = 38\n",
    "net.ForwardTT(sentences[n])\n",
    "blah = read_sentence(sentences[n])\n",
    "print('Input:      '+blah)\n",
    "print('Prediction: '+blah+net.Generate(5))\n",
    "print('Actual:     '+blah+read_sentence(sentences[n+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harles dar\n",
      "harles darwin intth \n"
     ]
    }
   ],
   "source": [
    "blah = 'harles dar'\n",
    "x = [char_indices[c] for c in blah]\n",
    "net.ForwardTT(x)\n",
    "print(blah)\n",
    "print(blah+net.Generate(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my accuracy:87.94674142%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "counter = 0\n",
    "for i in range(len(sentences)):\n",
    "    net.ForwardTT(sentences[i])\n",
    "    predResult = net.Generate()\n",
    "    # compare to see if the predicted result are the same\n",
    "    ConvertedVec = index2vec(next_chars[i][-1])\n",
    "    convertedChar = vec2char(ConvertedVec)\n",
    "    if predResult == convertedChar:\n",
    "        counter +=1\n",
    "        \n",
    "fraction = round(counter/len(sentences) * 100, 10)\n",
    "print(\"my accuracy:\"+str(round(counter/len(sentences),10)*100)+\"%\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
